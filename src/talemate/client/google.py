import json
import os

import pydantic
import structlog
from google import genai
import google.genai.types as genai_types
from google.genai.errors import APIError

from talemate.client.base import ClientBase, ErrorAction, ExtraField, ParameterReroute, CommonDefaults
from talemate.client.registry import register
from talemate.client.remote import (
    RemoteServiceMixin,
    EndpointOverride,
    EndpointOverrideMixin,
    endpoint_override_extra_fields,
)
from talemate.config import Client as BaseClientConfig
from talemate.config import load_config
from talemate.emit import emit
from talemate.emit.signals import handlers
from talemate.util import count_tokens

__all__ = [
    "GoogleClient",
]
log = structlog.get_logger("talemate")

# Edit this to add new models / remove old models
SUPPORTED_MODELS = [
    "gemini-1.0-pro",
    "gemini-1.5-pro-preview-0409",
    "gemini-1.5-flash",
    "gemini-1.5-flash-8b",
    "gemini-1.5-pro",
    "gemini-2.0-flash",
    "gemini-2.0-flash-lite",
    "gemini-2.5-flash-preview-04-17",
    "gemini-2.5-flash-preview-05-20",
    "gemini-2.5-pro-preview-03-25",
    "gemini-2.5-pro-preview-06-05",
]

class Defaults(EndpointOverride, CommonDefaults, pydantic.BaseModel):
    max_token_length: int = 16384
    model: str = "gemini-2.0-flash"
    disable_safety_settings: bool = False
    double_coercion: str = None

class ClientConfig(EndpointOverride, BaseClientConfig):
    disable_safety_settings: bool = False


@register()
class GoogleClient(EndpointOverrideMixin, RemoteServiceMixin, ClientBase):
    """
    Google client for generating text.
    """

    client_type = "google"
    conversation_retries = 0
    auto_break_repetition_enabled = False
    decensor_enabled = True
    config_cls = ClientConfig

    class Meta(ClientBase.Meta):
        name_prefix: str = "Google"
        title: str = "Google"
        manual_model: bool = True
        manual_model_choices: list[str] = SUPPORTED_MODELS
        requires_prompt_template: bool = False
        defaults: Defaults = Defaults()
        extra_fields: dict[str, ExtraField] = {
            "disable_safety_settings": ExtraField(
                name="disable_safety_settings",
                type="bool",
                label="Disable Safety Settings",
                required=False,
                description="Disable Google's safety settings for responses generated by the model.",
            ),
        }
        extra_fields.update(endpoint_override_extra_fields())
        

    def __init__(self, model="gemini-2.0-flash", **kwargs):
        self.model_name = model
        self.setup_status = None
        self.model_instance = None
        self.disable_safety_settings = kwargs.get("disable_safety_settings", False)
        self.google_credentials_read = False
        self.google_project_id = None
        self._reconfigure_endpoint_override(**kwargs)
        self.config = load_config()
        super().__init__(**kwargs)

        handlers["config_saved"].connect(self.on_config_saved)

    @property
    def can_be_coerced(self) -> bool:
        return True

    @property
    def google_credentials(self):
        path = self.google_credentials_path
        if not path:
            return None
        with open(path) as f:
            return json.load(f)

    @property
    def google_credentials_path(self):
        return self.config.get("google").get("gcloud_credentials_path")

    @property
    def google_location(self):
        return self.config.get("google").get("gcloud_location")
    
    @property
    def google_api_key(self):
        return self.config.get("google").get("api_key")

    @property
    def vertexai_ready(self) -> bool:
        return all([
            self.google_credentials_path,
            self.google_location,
        ])

    @property
    def developer_api_ready(self) -> bool:
        return all([
            self.google_api_key,
        ])
    
    @property
    def using(self) -> str:
        if self.developer_api_ready:
            return "API"
        if self.vertexai_ready:
            return "VertexAI"
        return "Unknown"

    @property
    def ready(self):
        # all google settings must be set
        return self.vertexai_ready or self.developer_api_ready or self.endpoint_override_base_url_configured

    @property
    def safety_settings(self):
        if not self.disable_safety_settings:
            return None

        safety_settings = [
            genai_types.SafetySetting(
                category="HARM_CATEGORY_SEXUALLY_EXPLICIT",
                threshold="BLOCK_NONE",
            ),
            genai_types.SafetySetting(
                category="HARM_CATEGORY_DANGEROUS_CONTENT",
                threshold="BLOCK_NONE",
            ),
            genai_types.SafetySetting(
                category="HARM_CATEGORY_HARASSMENT",
                threshold="BLOCK_NONE",
            ),
            genai_types.SafetySetting(
                category="HARM_CATEGORY_HATE_SPEECH",
                threshold="BLOCK_NONE",
            ),
            genai_types.SafetySetting(
                category="HARM_CATEGORY_CIVIC_INTEGRITY",
                threshold="BLOCK_NONE",
            ),
        ]

        return safety_settings

    @property
    def http_options(self) -> genai_types.HttpOptions | None:
        if not self.endpoint_override_base_url_configured:
            return None
        
        return genai_types.HttpOptions(
            base_url=self.base_url
        )

    @property
    def supported_parameters(self):
        return [
            "temperature",
            "top_p",
            "top_k",
            ParameterReroute(
                talemate_parameter="max_tokens", client_parameter="max_output_tokens"
            ),
            ParameterReroute(
                talemate_parameter="stopping_strings", client_parameter="stop_sequences"
            ),
        ]

    def emit_status(self, processing: bool = None):
        error_action = None
        if processing is not None:
            self.processing = processing

        if self.ready:
            status = "busy" if self.processing else "idle"
            model_name = self.model_name
        else:
            status = "error"
            model_name = "Setup incomplete"
            error_action = ErrorAction(
                title="Setup Google API credentials",
                action_name="openAppConfig",
                icon="mdi-key-variant",
                arguments=[
                    "application",
                    "google_api",
                ],
            )

        if not self.model_name:
            status = "error"
            model_name = "No model loaded"

        self.current_status = status
        data = {
            "double_coercion": self.double_coercion,
            "error_action": error_action.model_dump() if error_action else None,
            "meta": self.Meta().model_dump(),
            "enabled": self.enabled,
        }
        data.update(self._common_status_data()) 
        self.populate_extra_fields(data)

        if self.using == "VertexAI":
            details = f"{model_name} (VertexAI)"
        else:
            details = model_name

        emit(
            "client_status",
            message=self.client_type,
            id=self.name,
            details=details,
            status=status if self.enabled else "disabled",
            data=data,
        )

    def set_client_base_url(self, base_url: str | None):
        if getattr(self, "client", None):
            try:
                self.client.http_options.base_url = base_url
            except Exception as e:
                log.error("Error setting client base URL", error=e, client=self.client_type)

    def set_client(self, max_token_length: int = None, **kwargs):
        if not self.ready:
            log.error("Google cloud setup incomplete")
            if self.setup_status:
                self.setup_status = False
                emit("request_client_status")
                emit("request_agent_status")
            return

        if not self.model_name:
            self.model_name = "gemini-2.0-flash"

        if max_token_length and not isinstance(max_token_length, int):
            max_token_length = int(max_token_length)

        if self.google_credentials_path:
            os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = self.google_credentials_path

        model = self.model_name

        self.max_token_length = max_token_length or 16384

        if self.vertexai_ready and not self.developer_api_ready:
            self.client = genai.Client(
                vertexai=True,
                project=self.google_project_id,
                location=self.google_location,
            )
        else:
            self.client = genai.Client(api_key=self.api_key or None, http_options=self.http_options)

        log.info(
            "google set client",
            max_token_length=self.max_token_length,
            provided_max_token_length=max_token_length,
            model=model,
        )

    def response_tokens(self, response:str):
        """Return token count for a response which may be a string or SDK object."""
        return count_tokens(response)

    def prompt_tokens(self, prompt: str):
        return count_tokens(prompt)

    def reconfigure(self, **kwargs):
        if kwargs.get("model"):
            self.model_name = kwargs["model"]
            self.set_client(kwargs.get("max_token_length"))

        if "disable_safety_settings" in kwargs:
            self.disable_safety_settings = kwargs["disable_safety_settings"]

        if "enabled" in kwargs:
            self.enabled = bool(kwargs["enabled"])
            
        if "double_coercion" in kwargs:
            self.double_coercion = kwargs["double_coercion"]
            
        self._reconfigure_common_parameters(**kwargs)

    def clean_prompt_parameters(self, parameters: dict):
        super().clean_prompt_parameters(parameters)

        # if top_k is 0, remove it
        if "top_k" in parameters and parameters["top_k"] == 0:
            del parameters["top_k"]

    def prompt_template(self, system_message: str, prompt: str):
        """
        Google handles the prompt template internally, so we just
        give the prompt as is.
        """
        return prompt


    async def generate(self, prompt: str, parameters: dict, kind: str):
        """
        Generates text from the given prompt and parameters.
        """

        if not self.ready:
            raise Exception("Google setup incomplete")

        prompt, coercion_prompt = self.split_prompt_for_coercion(prompt)

        human_message = prompt.strip()
        system_message = self.get_system_message(kind)
        
        contents = [
            genai_types.Content(
                role="user",
                parts=[
                    genai_types.Part.from_text(
                        text=human_message,
                    )
                ]
            )
        ]
        
        if coercion_prompt:
            contents.append(
                genai_types.Content(
                    role="model",
                    parts=[
                        genai_types.Part.from_text(
                            text=coercion_prompt,
                        )
                    ]
                )
            )

        self.log.debug(
            "generate",
            base_url=self.base_url,
            prompt=prompt[:128] + " ...",
            parameters=parameters,
            system_message=system_message,
            disable_safety_settings=self.disable_safety_settings,
            safety_settings=self.safety_settings,
        )

        try:
            # Use streaming so we can update_Request_tokens incrementally
            #stream = await chat.send_message_async(
            #    human_message,
            #    safety_settings=self.safety_settings,
            #    generation_config=parameters,
            #    stream=True
            #)

            
            stream = await self.client.aio.models.generate_content_stream(
                model=self.model_name,
                contents=contents,
                config=genai_types.GenerateContentConfig(
                    safety_settings=self.safety_settings,
                    http_options=self.http_options,
                    **parameters
                ),
            )
            
            response = ""

            async for chunk in stream:
                # For each streamed chunk, append content and update token counts
                content_piece = getattr(chunk, "text", None)
                if not content_piece:
                    # Some SDK versions wrap text under candidates[0].text
                    try:
                        content_piece = chunk.candidates[0].text  # type: ignore
                    except Exception:
                        content_piece = None

                if content_piece:
                    response += content_piece
                    # Incrementally update token usage
                    self.update_request_tokens(count_tokens(content_piece))

            # Store total token accounting for prompt/response
            self._returned_prompt_tokens = self.prompt_tokens(prompt)
            self._returned_response_tokens = self.response_tokens(response)

            log.debug("generated response", response=response)

            return response

        except APIError as e:
            self.log.error("generate error", e=e)
            emit("status", message="google API: API Error", status="error")
            return ""
        except Exception as e:
            raise
