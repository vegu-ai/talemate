# Settings

## General

![Conversation agent general settings](/talemate/img/0.28.0/conversation-general-settings.png)

!!! note "Inference perameters"
    Inference parameters are NOT configured through any individual agent.

    Please see the [Inference presets](/talemate/user-guide/clients/presets) section for more information on how to configure inference parameters.

##### Client

The text-generation client to use for conversation generation.

##### Auto Break Repetition

If checked and talemate detects a repetitive response (based on a threshold), it will automatically re-generate the resposne with increased randomness parameters.

##### Natural Flow

When there are multiple characters in the scene, this will help the AI to keep the conversation flowing naturally, making sure turns are somewhat evenly distributed, and also checking that the most relevant character gets the next turn, based on the context.

##### Max. Auto turns

Maximum turns the AI gets in succession, before the player gets a turn no matter what.

##### Max. Idle turns

The maximum number of turns a character can go without speaking before the AI will force them to speak.

##### Long Term Memory

If checked will inject relevant information into the context using relevancy through the [Memory Agent](/talemate/user-guide/agents/memory).

##### Context Retrieval Method

What method to use for long term memory selection

- `Context queries based on recent context` - will take the last 3 messages in the scene and select relevant context from them. This is the fastest method, but may not always be the most relevant.
- `Context queries generated by AI` - will generate a set of context queries based on the current scene and select relevant context from them. This is slower, but may be more relevant.
- `AI compiled questions and answers` - will use the AI to generate a set of questions and answers based on the current scene and select relevant context from them. This is the slowest, and not necessarily better than the other methods.

## Generation

![Conversation agent generation settings](/talemate/img/0.28.0/conversation-generation-settings.png)

##### Format

The dialogue format as the AI will see it.

This currently comes in two choices: 

- `Screenplay`
- `Chat (legacy)`

Visually this will make no difference to what you see, it may however affect how the AI interprets the dialogue.

##### Generation Length

The maximum length of the generated dialogue. (tokens)

##### Jiggle

The amount of randomness to apply to the generation. This can help to avoid repetitive responses.

##### Task Instructions

Extra instructions for the generation. This should be short and generic as it will be applied for all characters. This will be appended to the existing task instrunctions in the conversation prompt BEFORE the conversation history.

##### Actor Instructions

General, broad isntructions for ALL actors in the scene. This will be appended to the existing actor instructions in the conversation prompt AFTER the conversation history.

##### Actor Instructions Offset

If > 0 will offset the instructions for the actor (both broad and character specific) into the history by that many turns. Some LLMs struggle to generate coherent continuations if the scene is interrupted by instructions right before the AI is asked to generate dialogue. This allows to shift the instruction backwards.

## Context Investigation

A new :material-flask: experimental feature introduced in `0.28.0` alongside the [layered history summarization](/talemate/user-guide/agents/summarizer/settings#layered-history).

If enabled, the AI will investigate the history for relevant information to include in the conversation prompt. Investigation works by digging through the various layers of the history, and extracting relevant information based on the final message in the scene.

This can be **very slow** depending on how many layers are enabled and generated. It can lead to a great improvement in the quality of the generated dialogue, but it currently still is a mixed bag. A strong LLM is almost a hard requirement for it produce anything useful. 22B+ models are recommended.

![Conversation agent context investigation settings](/talemate/img/0.28.0/conversation-context-investigation-settings.png)

!!! note "Tips"
    - This is experimental and results WILL vary in quality.
    - Requires a strong LLM. 22B+ models are recommended.
    - Good, clean summarization of the history is a hard requirement for this to work well. Regenerate your history if it's messy. (World Editor -> History -> Regenerate)

##### Enable context investigation

Enable or disable the context investigation feature.

##### Trigger

Allows you to specify when the context investigation should be triggered.

- Agent decides - the AI will decide when to trigger the context investigation based on the scene.
- Only when a question is asked - the AI will only trigger the context investigation when a question is asked.

